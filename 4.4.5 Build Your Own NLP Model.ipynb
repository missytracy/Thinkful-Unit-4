{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import state_union, stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4.5 Challenge - Build Your Own NLP Model\n",
    "\n",
    "For this challenge, you will need to choose a corpus of data from nltk or another source that includes categories you can predict and create an analysis pipeline that includes the following steps:\n",
    "\n",
    "1. Data cleaning / processing / language parsing\n",
    "2. Create features using two different NLP methods: For example, BoW vs tf-idf.\n",
    "3. Use the features to fit supervised learning models for each feature set to predict the category outcomes.  Use cross-validation and determine whether one model performed better.\n",
    "5. Pick one of the models and try to increase accuracy by at least 5 percentage points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1945-Truman.txt',\n",
       " '1946-Truman.txt',\n",
       " '1947-Truman.txt',\n",
       " '1948-Truman.txt',\n",
       " '1949-Truman.txt',\n",
       " '1950-Truman.txt',\n",
       " '1951-Truman.txt',\n",
       " '1953-Eisenhower.txt',\n",
       " '1954-Eisenhower.txt',\n",
       " '1955-Eisenhower.txt',\n",
       " '1956-Eisenhower.txt',\n",
       " '1957-Eisenhower.txt',\n",
       " '1958-Eisenhower.txt',\n",
       " '1959-Eisenhower.txt',\n",
       " '1960-Eisenhower.txt',\n",
       " '1961-Kennedy.txt',\n",
       " '1962-Kennedy.txt',\n",
       " '1963-Johnson.txt',\n",
       " '1963-Kennedy.txt',\n",
       " '1964-Johnson.txt',\n",
       " '1965-Johnson-1.txt',\n",
       " '1965-Johnson-2.txt',\n",
       " '1966-Johnson.txt',\n",
       " '1967-Johnson.txt',\n",
       " '1968-Johnson.txt',\n",
       " '1969-Johnson.txt',\n",
       " '1970-Nixon.txt',\n",
       " '1971-Nixon.txt',\n",
       " '1972-Nixon.txt',\n",
       " '1973-Nixon.txt',\n",
       " '1974-Nixon.txt',\n",
       " '1975-Ford.txt',\n",
       " '1976-Ford.txt',\n",
       " '1977-Ford.txt',\n",
       " '1978-Carter.txt',\n",
       " '1979-Carter.txt',\n",
       " '1980-Carter.txt',\n",
       " '1981-Reagan.txt',\n",
       " '1982-Reagan.txt',\n",
       " '1983-Reagan.txt',\n",
       " '1984-Reagan.txt',\n",
       " '1985-Reagan.txt',\n",
       " '1986-Reagan.txt',\n",
       " '1987-Reagan.txt',\n",
       " '1988-Reagan.txt',\n",
       " '1989-Bush.txt',\n",
       " '1990-Bush.txt',\n",
       " '1991-Bush-1.txt',\n",
       " '1991-Bush-2.txt',\n",
       " '1992-Bush.txt',\n",
       " '1993-Clinton.txt',\n",
       " '1994-Clinton.txt',\n",
       " '1995-Clinton.txt',\n",
       " '1996-Clinton.txt',\n",
       " '1997-Clinton.txt',\n",
       " '1998-Clinton.txt',\n",
       " '1999-Clinton.txt',\n",
       " '2000-Clinton.txt',\n",
       " '2001-GWBush-1.txt',\n",
       " '2001-GWBush-2.txt',\n",
       " '2002-GWBush.txt',\n",
       " '2003-GWBush.txt',\n",
       " '2004-GWBush.txt',\n",
       " '2005-GWBush.txt',\n",
       " '2006-GWBush.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Presidential State of the Unions file ids\n",
    "#state_union.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab first speech given by Bush and Clinton\n",
    "clinton = state_union.raw('1993-Clinton.txt')\n",
    "bush = state_union.raw('1989-Bush.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse using SpaCy\n",
    "nlp = spacy.load('en')\n",
    "clinton_doc = nlp(clinton)\n",
    "bush_doc = nlp(bush)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(PRESIDENT, GEORGE, H.W., BUSH, 'S)</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(ADDRESS, ON, ADMINISTRATION, GOALS)</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(BEFORE, A, JOINT, SESSION, OF, CONGRESS, \\n \\...</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Mr., Speaker, ,, Mr., President, ,, and, dist...</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Less, than, 3, weeks, ago, ,, I, joined, you,...</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0     1\n",
       "0                (PRESIDENT, GEORGE, H.W., BUSH, 'S)  Bush\n",
       "1               (ADDRESS, ON, ADMINISTRATION, GOALS)  Bush\n",
       "2  (BEFORE, A, JOINT, SESSION, OF, CONGRESS, \\n \\...  Bush\n",
       "3  (Mr., Speaker, ,, Mr., President, ,, and, dist...  Bush\n",
       "4  (Less, than, 3, weeks, ago, ,, I, joined, you,...  Bush"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group into sentences\n",
    "bush_sents = [[sent, 'Bush'] for sent in bush_doc.sents]\n",
    "clinton_sents = [[sent, 'Clinton'] for sent in clinton_doc.sents]\n",
    "\n",
    "# Combine\n",
    "sentences = pd.DataFrame(bush_sents + clinton_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRESIDENT GEORGE H.W. BUSH'S ADDRESS ON ADMINISTRATION GOALS BEFORE A JOINT SESSION OF CONGRESS\n",
      " \n",
      "February 9, 1989 \n",
      "\n",
      "Mr. Speaker, Mr. President, and distinguished Members of the House and Senate, honored guests, and fellow citizens: Less than 3 weeks ago, I joined you on the West Front of this very building and, looking over the monuments to our proud past, offered you my hand in filling the next page of American history with a story of extended prosperity and continued peace. And tonight I'm back to offer\n",
      "\n",
      "Bush speech length: 5685\n",
      "\n",
      " PRESIDENT BILL CLINTON'S ADDRESS BEFORE A JOINT SESSION OF THE CONGRESS ON THE STATE OF THE UNION\n",
      " \n",
      "February 17, 1993 \n",
      "\n",
      "Mr. President, Mr. Speaker, Members of the House and the Senate, distinguished Americans here as visitors in this Chamber, as am I. It is nice to have a fresh excuse for giving a long speech. [Laughter]\n",
      "When Presidents speak to Congress and the Nation from this podium, typically they comment on the full range and challenges and opportunities that face the United States. But this is\n",
      "\n",
      "Clinton speech length: 7920\n"
     ]
    }
   ],
   "source": [
    "# Look at excerpts from each \n",
    "print(bush_doc[:100])\n",
    "print('\\nBush speech length:', len(bush_doc))\n",
    "\n",
    "print('\\n', clinton_doc[:100])\n",
    "print('\\nClinton speech length:', len(clinton_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bag of words function for each text\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # filter out punctuation and stop words\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return most common words\n",
    "    return [item[0] for item in Counter(allwords).most_common(500)]\n",
    "\n",
    "# Get bags \n",
    "bush_words = bag_of_words(bush_doc)\n",
    "clinton_words = bag_of_words(clinton_doc)\n",
    "\n",
    "# Combine bags to create common set of unique words\n",
    "common_words = set(bush_words + clinton_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bag of words data frame using combined common words and sentences\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Build data frame\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentences in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentences\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>moral</th>\n",
       "      <th>approximately</th>\n",
       "      <th>prepared</th>\n",
       "      <th>coast</th>\n",
       "      <th>disease</th>\n",
       "      <th>rudman</th>\n",
       "      <th>spread</th>\n",
       "      <th>50</th>\n",
       "      <th>produce</th>\n",
       "      <th>angeles</th>\n",
       "      <th>...</th>\n",
       "      <th>company</th>\n",
       "      <th>punish</th>\n",
       "      <th>urgent</th>\n",
       "      <th>general</th>\n",
       "      <th>sector</th>\n",
       "      <th>party</th>\n",
       "      <th>ought</th>\n",
       "      <th>land</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(PRESIDENT, GEORGE, H.W., BUSH, 'S)</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(ADDRESS, ON, ADMINISTRATION, GOALS)</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(BEFORE, A, JOINT, SESSION, OF, CONGRESS, \\n \\...</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Mr., Speaker, ,, Mr., President, ,, and, dist...</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Less, than, 3, weeks, ago, ,, I, joined, you,...</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 753 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  moral approximately prepared coast disease rudman spread 50 produce angeles  \\\n",
       "0     0             0        0     0       0      0      0  0       0       0   \n",
       "1     0             0        0     0       0      0      0  0       0       0   \n",
       "2     0             0        0     0       0      0      0  0       0       0   \n",
       "3     0             0        0     0       0      0      0  0       0       0   \n",
       "4     0             0        0     0       0      0      0  0       0       0   \n",
       "\n",
       "      ...     company punish urgent general sector party ought land  \\\n",
       "0     ...           0      0      0       0      0     0     0    0   \n",
       "1     ...           0      0      0       0      0     0     0    0   \n",
       "2     ...           0      0      0       0      0     0     0    0   \n",
       "3     ...           0      0      0       0      0     0     0    0   \n",
       "4     ...           0      0      0       0      0     0     0    0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0                (PRESIDENT, GEORGE, H.W., BUSH, 'S)        Bush  \n",
       "1               (ADDRESS, ON, ADMINISTRATION, GOALS)        Bush  \n",
       "2  (BEFORE, A, JOINT, SESSION, OF, CONGRESS, \\n \\...        Bush  \n",
       "3  (Mr., Speaker, ,, Mr., President, ,, and, dist...        Bush  \n",
       "4  (Less, than, 3, weeks, ago, ,, I, joined, you,...        Bush  \n",
       "\n",
       "[5 rows x 753 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create bow features \n",
    "bow = bow_features(sentences, common_words)\n",
    "bow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab sentence level documents in NLTK\n",
    "clinton = state_union.sents('1993-Clinton.txt')\n",
    "bush = state_union.sents('1989-Bush.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of text \n",
    "clinton_list = [\" \".join(sent) for sent in clinton]\n",
    "bush_list = [\" \".join(sent) for sent in bush]\n",
    "joined = clinton_list + bush_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, \n",
    "                             min_df=2, \n",
    "                             stop_words='english',   \n",
    "                             use_idf=True,\n",
    "                             norm=u'l2', \n",
    "                             smooth_idf=True \n",
    "                            )\n",
    "\n",
    "tfidf = vectorizer.fit_transform(joined).tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning Models\n",
    "Evaluate each feature set using cross validation.  Models tested: Logistic Regression, Random Forest, & Gradient Boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Specify model inputs for each feature set\n",
    "\n",
    "# BoW\n",
    "X_bow = bow.drop(['text_sentence', 'text_source'], 1)\n",
    "Y_bow = bow['text_source']\n",
    "\n",
    "# Tfidf\n",
    "X_tfidf = tfidf\n",
    "Y_tfidf = ['Clinton']*len(clinton_list) + ['Bush']*len(bush_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Logistic Regression Scores:  [0.625      0.63333333 0.65546218 0.71428571 0.72881356]\n",
      "Avg Score: 0.6713789583630062\n",
      "\n",
      "Tfidf Logistic Regression Scores: [0.58474576 0.69491525 0.66666667 0.77586207 0.76724138]\n",
      "Avg Score: 0.6978862263783363\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# BoW\n",
    "lr = LogisticRegression()\n",
    "lr_bow = lr.fit(X_bow, Y_bow)\n",
    "print('BoW Logistic Regression Scores: ', cross_val_score(lr_bow, X_bow, Y_bow, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(lr_bow, X_bow, Y_bow, cv=5)))\n",
    "\n",
    "# Tfidf\n",
    "lr = LogisticRegression()\n",
    "lr_tfidf = lr.fit(X_tfidf, Y_tfidf)\n",
    "print('\\nTfidf Logistic Regression Scores:', cross_val_score(lr_tfidf, X_tfidf, Y_tfidf, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(lr_tfidf, X_tfidf, Y_tfidf, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Random Forest Scores:  [0.6        0.60833333 0.56302521 0.64705882 0.62711864]\n",
      "Avg Score: 0.6325383373688459\n",
      "\n",
      "Tfidf Random Forest Scores: [0.52542373 0.58474576 0.62393162 0.68103448 0.6637931 ]\n",
      "Avg Score: 0.5967782623247263\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "# BoW\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "rfc_bow = rfc.fit(X_bow, Y_bow)\n",
    "print('BoW Random Forest Scores: ', cross_val_score(rfc_bow, X_bow, Y_bow, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(rfc_bow, X_bow, Y_bow, cv=5)))\n",
    "\n",
    "# Tfidf\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "rfc_tfidf = rfc.fit(X_tfidf, Y_tfidf)\n",
    "print('\\nTfidf Random Forest Scores:', cross_val_score(rfc_tfidf, X_tfidf, Y_tfidf, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(rfc_tfidf, X_tfidf, Y_tfidf, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bow Gradient Boosting Scores: [0.66666667 0.625      0.67226891 0.69747899 0.6779661 ]\n",
      "Avg Score: 0.654430280586811\n",
      "\n",
      "Tfidf Random Forest Scores: [0.62711864 0.66949153 0.60683761 0.74137931 0.67241379]\n",
      "Avg Score: 0.6634481759554817\n"
     ]
    }
   ],
   "source": [
    "# BoW\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "clf_bow = clf.fit(X_bow, Y_bow)\n",
    "print('Bow Gradient Boosting Scores:', cross_val_score(clf_bow, X_bow,Y_bow, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(clf_bow, X_bow, Y_bow, cv=5)))\n",
    "\n",
    "# Tfidf\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "clf_tfidf = clf.fit(X_tfidf, Y_tfidf)\n",
    "print('\\nTfidf Random Forest Scores:', cross_val_score(clf_tfidf, X_tfidf, Y_tfidf, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(clf_tfidf, X_tfidf, Y_tfidf, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick A Model and Try to Increase Accuracy by 5%\n",
    "\n",
    "__Model: Logistic Regression Using BoW Feature Set__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase BoW size\n",
    "\n",
    "# Update function to include 1000 most common words\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # filter out punctuation and stop words\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return most common words\n",
    "    return [item[0] for item in Counter(allwords).most_common(1000)]\n",
    "\n",
    "# Get bags \n",
    "bush_words = bag_of_words(bush_doc)\n",
    "clinton_words = bag_of_words(clinton_doc)\n",
    "\n",
    "# Combine bags to create common set of unique words\n",
    "common_words = set(bush_words + clinton_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bow features \n",
    "big_bow = bow_features(sentences, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative</th>\n",
       "      <th>minimize</th>\n",
       "      <th>costly</th>\n",
       "      <th>toxic</th>\n",
       "      <th>middle</th>\n",
       "      <th>trend</th>\n",
       "      <th>reverse</th>\n",
       "      <th>important</th>\n",
       "      <th>free</th>\n",
       "      <th>700,000</th>\n",
       "      <th>...</th>\n",
       "      <th>strength</th>\n",
       "      <th>importantly</th>\n",
       "      <th>roll</th>\n",
       "      <th>destiny</th>\n",
       "      <th>alaska</th>\n",
       "      <th>ought</th>\n",
       "      <th>constitutional</th>\n",
       "      <th>land</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(PRESIDENT, GEORGE, H.W., BUSH, 'S)</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(ADDRESS, ON, ADMINISTRATION, GOALS)</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(BEFORE, A, JOINT, SESSION, OF, CONGRESS, \\n \\...</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Mr., Speaker, ,, Mr., President, ,, and, dist...</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Less, than, 3, weeks, ago, ,, I, joined, you,...</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1557 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  relative minimize costly toxic middle trend reverse important free 700,000  \\\n",
       "0        0        0      0     0      0     0       0         0    0       0   \n",
       "1        0        0      0     0      0     0       0         0    0       0   \n",
       "2        0        0      0     0      0     0       0         0    0       0   \n",
       "3        0        0      0     0      0     0       0         0    0       0   \n",
       "4        0        0      0     0      0     0       0         0    0       0   \n",
       "\n",
       "      ...     strength importantly roll destiny alaska ought constitutional  \\\n",
       "0     ...            0           0    0       0      0     0              0   \n",
       "1     ...            0           0    0       0      0     0              0   \n",
       "2     ...            0           0    0       0      0     0              0   \n",
       "3     ...            0           0    0       0      0     0              0   \n",
       "4     ...            0           0    0       0      0     0              0   \n",
       "\n",
       "  land                                      text_sentence text_source  \n",
       "0    0                (PRESIDENT, GEORGE, H.W., BUSH, 'S)        Bush  \n",
       "1    0               (ADDRESS, ON, ADMINISTRATION, GOALS)        Bush  \n",
       "2    0  (BEFORE, A, JOINT, SESSION, OF, CONGRESS, \\n \\...        Bush  \n",
       "3    0  (Mr., Speaker, ,, Mr., President, ,, and, dist...        Bush  \n",
       "4    0  (Less, than, 3, weeks, ago, ,, I, joined, you,...        Bush  \n",
       "\n",
       "[5 rows x 1557 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW (big) Logistic Regression Scores:  [0.60833333 0.625      0.63865546 0.72268908 0.72033898]\n",
      "Avg. Score  0.6630033708398614\n"
     ]
    }
   ],
   "source": [
    "# Make new X and Y inputs\n",
    "X_big_bow = big_bow.drop(['text_sentence', 'text_source'], 1)\n",
    "Y_big_bow = big_bow['text_source']\n",
    "\n",
    "# Rerun BoW\n",
    "lr = LogisticRegression()\n",
    "lr_big_bow = lr.fit(X_big_bow, Y_big_bow)\n",
    "print('BoW (big) Logistic Regression Scores: ', cross_val_score(lr_big_bow, X_big_bow, Y_big_bow, cv=5))\n",
    "print('Avg. Score ', np.mean(cross_val_score(lr_big_bow, X_big_bow, Y_big_bow, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a bigger bag of words actually made the average score get worse by about 1%.  Try out another method - include punctuation in BoW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update function, go back to 500 most common words and add in punctuation\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # filter out punctuation and stop words\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_stop]\n",
    "                   \n",
    "    # Return most common words\n",
    "    return [item[0] for item in Counter(allwords).most_common(500)]\n",
    "\n",
    "# Get bags \n",
    "bush_words = bag_of_words(bush_doc)\n",
    "clinton_words = bag_of_words(clinton_doc)\n",
    "\n",
    "# Combine bags to create common set of unique words\n",
    "common_words = set(bush_words + clinton_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bow features \n",
    "bow = bow_features(sentences, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regenerate model features\n",
    "X_bow = bow.drop(['text_sentence', 'text_source'], 1)\n",
    "Y_bow = bow['text_source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW #3 - Logistic Regression Scores:  [0.625      0.63333333 0.64705882 0.71428571 0.72881356]\n",
      "Avg. Score  0.6696982860940986\n"
     ]
    }
   ],
   "source": [
    "# Rerun model\n",
    "lr = LogisticRegression(\n",
    "    )\n",
    "lr_bow = lr.fit(X_bow, Y_bow)\n",
    "print('BoW #3 - Logistic Regression Scores: ', cross_val_score(lr_bow, X_bow, Y_bow, cv=5))\n",
    "print('Avg. Score ', np.mean(cross_val_score(lr_bow, X_bow, Y_bow, cv=5)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
